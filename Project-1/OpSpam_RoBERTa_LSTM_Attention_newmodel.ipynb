{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiFP0ZKX4qqS"
      },
      "source": [
        "\n",
        "# OpSpam Replication: RoBERTa(+LSTM) **and** TFâ€‘IDF + Logistic Baseline\n",
        "\n",
        "This notebook is pre-configured for your CSV with columns:\n",
        "- **`text`**: review text\n",
        "- **`deceptive`**: binary label (1 = deceptive, 0 = truthful)\n",
        "\n",
        "It trains **two models** and reports comparable metrics/plots:\n",
        "1. **Baseline:** TFâ€‘IDF + Logistic Regression (mirrors your demo)\n",
        "2. **RoBERTa (+ optional LSTM)** classifier\n",
        "\n",
        "Exports: metrics CSVs, confusion matrix, ROC and PR curves, and a sideâ€‘byâ€‘side table.\n"
      ],
      "id": "GiFP0ZKX4qqS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkrbE8m74qqT"
      },
      "source": [
        "# Setup"
      ],
      "id": "VkrbE8m74qqT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY6o24-64qqT"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "#@title â¬‡ï¸ Install dependencies\n",
        "!pip -q install transformers==4.44.2 datasets==2.21.0 accelerate==0.34.2 scikit-learn==1.5.1 matplotlib==3.9.0 torch==2.3.1 -U\n",
        "\n",
        "import os, random, math, json, sys, time, re\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, roc_auc_score, average_precision_score,\n",
        "    classification_report, roc_curve, precision_recall_curve\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModel, AutoConfig,\n",
        "    TrainingArguments, Trainer\n",
        ")\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device:\", device)\n"
      ],
      "id": "xY6o24-64qqT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXToSqBz4qqU"
      },
      "source": [
        "# Configuration"
      ],
      "id": "bXToSqBz4qqU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR-_Q4pW4qqU"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "#@title âš™ï¸ Configuration\n",
        "MODEL_NAME = \"roberta-base\"  #@param [\"roberta-base\"]\n",
        "MAX_LEN = 256  #@param {type:\"integer\"}\n",
        "BATCH_SIZE = 32  #@param {type:\"integer\"}\n",
        "EPOCHS = 8  #@param {type:\"integer\"}\n",
        "LEARNING_RATE = 2e-5  #@param {type:\"number\"}\n",
        "WEIGHT_DECAY = 0.01  #@param {type:\"number\"}\n",
        "SEED = 42  #@param {type:\"integer\"}\n",
        "USE_LSTM = True  #@param {type:\"boolean\"}\n",
        "LSTM_HIDDEN = 128  #@param {type:\"integer\"}\n",
        "DROPOUT = 0.6  #@param {type:\"number\"}\n",
        "\n",
        "# Baseline config\n",
        "TFIDF_MAX_FEATURES = 5000  #@param {type:\"integer\"}\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(SEED)\n"
      ],
      "id": "HR-_Q4pW4qqU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUXA1LbU4qqU"
      },
      "source": [
        "# Data"
      ],
      "id": "WUXA1LbU4qqU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVhe6OcM4qqU"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "#@title ðŸ“¥ Load data\n",
        "csv_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "if not csv_path or not os.path.exists(csv_path):\n",
        "    try:\n",
        "        from google.colab import files  # type: ignore\n",
        "        print(\"Upload 'deceptive-opinion.csv'\")\n",
        "        uploaded = files.upload()\n",
        "        csv_path = list(uploaded.keys())[0]\n",
        "    except Exception as e:\n",
        "        print(\"No Colab file picker. Falling back to default name.\")\n",
        "        csv_path = \"deceptive-opinion.csv\"\n",
        "\n",
        "assert os.path.exists(csv_path), f\"CSV not found at {csv_path}\"\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "display(df.head(3))\n"
      ],
      "id": "cVhe6OcM4qqU"
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_COL = \"deceptive\"  # make sure this is the right column name\n",
        "\n",
        "print(\"dtype:\", df[LABEL_COL].dtype)\n",
        "print(\"\\nRaw unique values (repr):\")\n",
        "raw_uniques = sorted({repr(x) for x in df[LABEL_COL].unique()})\n",
        "for u in raw_uniques:\n",
        "    print(\"  \", u)\n",
        "\n",
        "print(\"\\nValue counts (dropna=False):\")\n",
        "print(df[LABEL_COL].value_counts(dropna=False))\n"
      ],
      "metadata": {
        "id": "q9EJpf2UAagG"
      },
      "id": "q9EJpf2UAagG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2qiTdsc4qqU"
      },
      "source": [
        "# Columns & Quick Clean"
      ],
      "id": "r2qiTdsc4qqU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UColIqhG4qqU"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TEXT_COL  = \"text\"\n",
        "LABEL_COL = \"deceptive\"   # name is okay; values are strings\n",
        "\n",
        "# 1) Clean text like your demo (does NOT touch labels)\n",
        "df[TEXT_COL] = (\n",
        "    df[TEXT_COL].astype(str)\n",
        "                .str.lower()\n",
        "                .str.replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
        ")\n",
        "\n",
        "# 2) Robust label normalization â†’ map to {0,1}\n",
        "def norm(s):\n",
        "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
        "    return s.replace(\"\\u00A0\",\" \").strip().lower()   # strip NBSP and whitespace\n",
        "\n",
        "lab_norm = df[LABEL_COL].apply(norm)\n",
        "\n",
        "mapping = {\"truthful\": 0, \"deceptive\": 1, \"0\": 0, \"1\": 1}\n",
        "df[LABEL_COL] = lab_norm.map(mapping)\n",
        "\n",
        "# 3) Fail early if anything didnâ€™t map\n",
        "if df[LABEL_COL].isna().any():\n",
        "    bad = sorted(df.loc[df[LABEL_COL].isna(), LABEL_COL].unique())\n",
        "    raise ValueError(f\"Unrecognized label strings: {bad} â€” extend the mapping.\")\n",
        "\n",
        "# 4) Verify full dataset has both classes\n",
        "print(\"Full dataset counts:\", df[LABEL_COL].value_counts().sort_index().to_dict())\n",
        "assert set(df[LABEL_COL].unique()) == {0,1}, \"Dataset collapsed to one class.\"\n",
        "\n",
        "# 5) Stratified split (guarantees both classes appear in each split for balanced data)\n",
        "X = df[TEXT_COL].values\n",
        "y = df[LABEL_COL].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.10, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "def check_split(y, name):\n",
        "    uniq = np.unique(y)\n",
        "    print(f\"{name} classes:\", uniq, \"counts:\", {int(c): int((y==c).sum()) for c in uniq})\n",
        "    assert set(uniq) == {0,1}, f\"{name} has only one class ({uniq}).\"\n",
        "\n",
        "check_split(y,       \"All\")\n",
        "check_split(y_train, \"Train\")\n",
        "check_split(y_val,   \"Val\")\n",
        "check_split(y_test,  \"Test\")\n"
      ],
      "id": "UColIqhG4qqU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOGha_tZ4qqU"
      },
      "source": [
        "# Split"
      ],
      "id": "qOGha_tZ4qqU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RJ1xZSR4qqU"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "#@title ðŸ”€ Stratified split (80/20) and make a val split from train\n",
        "X = df[TEXT_COL].values\n",
        "y = df[LABEL_COL].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.10, random_state=SEED, stratify=y_train\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n"
      ],
      "id": "5RJ1xZSR4qqU"
    },
    {
      "cell_type": "code",
      "source": [
        "def check_split(y, name):\n",
        "    uniq = np.unique(y)\n",
        "    print(f\"{name} classes:\", uniq)\n",
        "    assert set(uniq) == {0,1}, (\n",
        "        f\"{name} has only one class ({uniq}). \"\n",
        "        \"Check label mapping/stratification or class distribution.\"\n",
        "    )\n",
        "\n",
        "check_split(y_train, \"Train\")\n",
        "check_split(y_val,   \"Val\")\n",
        "check_split(y_test,  \"Test\")\n"
      ],
      "metadata": {
        "id": "CYP2LrHV-rK7"
      },
      "id": "CYP2LrHV-rK7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w0h7jpK4qqU"
      },
      "source": [
        "# Baseline (TFâ€‘IDF + Logistic)"
      ],
      "id": "0w0h7jpK4qqU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnnD6UVu4qqU"
      },
      "source": [
        "# Tokenizer & Datasets"
      ],
      "id": "rnnD6UVu4qqU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9UyB0U64qqU"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "#@title ðŸ”¡ Tokenize for RoBERTa\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts; self.labels = labels\n",
        "        self.tokenizer = tokenizer; self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(\n",
        "            str(self.texts[idx]), padding=\"max_length\", truncation=True,\n",
        "            max_length=self.max_len, return_tensors=\"pt\"\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "train_ds = TextDataset(X_train, y_train, tokenizer, MAX_LEN)\n",
        "val_ds   = TextDataset(X_val, y_val, tokenizer, MAX_LEN)\n",
        "test_ds  = TextDataset(X_test, y_test, tokenizer, MAX_LEN)\n"
      ],
      "id": "X9UyB0U64qqU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h70jR4jQ4qqU"
      },
      "source": [
        "# Model"
      ],
      "id": "h70jR4jQ4qqU"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import RobertaModel\n",
        "\n",
        "class RobertaLSTMAttentionClassifier(nn.Module):  #Novel ml model with attention\n",
        "    def __init__(self,\n",
        "                 model_name: str = \"roberta-base\",\n",
        "                 lstm_hidden: int = 128,\n",
        "                 dropout: float = 0.6,\n",
        "                 use_lstm: bool = True,   # keep for compatibility\n",
        "                 num_labels: int = 2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_labels = num_labels\n",
        "        self.use_lstm = use_lstm\n",
        "\n",
        "        # RoBERTa encoder (same as before)\n",
        "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
        "        hidden_size = self.roberta.config.hidden_size\n",
        "\n",
        "        if use_lstm:\n",
        "            self.lstm = nn.LSTM(\n",
        "                input_size=hidden_size,\n",
        "                hidden_size=lstm_hidden,\n",
        "                num_layers=1,\n",
        "                batch_first=True,\n",
        "                bidirectional=True\n",
        "            )\n",
        "            feat_dim = lstm_hidden * 2  # biLSTM\n",
        "        else:\n",
        "            # fall back to using RoBERTa hidden size directly\n",
        "            self.lstm = None\n",
        "            feat_dim = hidden_size\n",
        "\n",
        "        # Self-attention over sequence features\n",
        "        self.attention = nn.Linear(feat_dim, 1, bias=False)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(feat_dim, num_labels)\n",
        "\n",
        "    def forward(self,\n",
        "                input_ids=None,\n",
        "                attention_mask=None,\n",
        "                labels=None,\n",
        "                **kwargs):\n",
        "\n",
        "        outputs = self.roberta(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=True\n",
        "        )\n",
        "        seq = outputs.last_hidden_state        # [B, T, H]\n",
        "\n",
        "        if self.use_lstm:\n",
        "            lstm_out, _ = self.lstm(seq)       # [B, T, 2*hidden]\n",
        "            feats = lstm_out\n",
        "        else:\n",
        "            feats = seq                        # [B, T, H]\n",
        "\n",
        "        # self-attention pooling\n",
        "        attn_scores = self.attention(feats).squeeze(-1)  # [B, T]\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(attention_mask == 0, -1e9)\n",
        "\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)    # [B, T]\n",
        "        attn_weights = attn_weights.unsqueeze(1)         # [B, 1, T]\n",
        "        context = torch.bmm(attn_weights, feats).squeeze(1)  # [B, feat_dim]\n",
        "\n",
        "        context = self.dropout(context)\n",
        "        logits = self.classifier(context)                # [B, num_labels]\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels),\n",
        "                            labels.view(-1))\n",
        "\n",
        "        if loss is not None:\n",
        "            return {\"loss\": loss, \"logits\": logits}\n",
        "        else:\n",
        "            return {\"logits\": logits}\n"
      ],
      "metadata": {
        "id": "2piFDSTRtKgc"
      },
      "id": "2piFDSTRtKgc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MoxpBxO4qqV"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "#@title ðŸ§  RoBERTa(+LSTM) model\n",
        "class RobertaLSTMClassifier(nn.Module):\n",
        "    def __init__(self, model_name, lstm_hidden=128, dropout=0.6, use_lstm=True):\n",
        "        super().__init__()\n",
        "        self.use_lstm = use_lstm\n",
        "        self.config = AutoConfig.from_pretrained(model_name)\n",
        "        self.roberta = AutoModel.from_pretrained(model_name, add_pooling_layer=False)\n",
        "        hidden = self.config.hidden_size\n",
        "        if self.use_lstm:\n",
        "            self.lstm = nn.LSTM(input_size=hidden, hidden_size=lstm_hidden,\n",
        "                                num_layers=1, batch_first=True, bidirectional=False)\n",
        "            feat = lstm_hidden\n",
        "        else:\n",
        "            feat = hidden\n",
        "        self.bn = nn.BatchNorm1d(feat)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.cls = nn.Linear(feat, 2)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
        "        out = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last = out.last_hidden_state\n",
        "        if self.use_lstm:\n",
        "            _, (h, _) = self.lstm(last)\n",
        "            feat = h.squeeze(0)\n",
        "        else:\n",
        "            feat = last[:,0,:]\n",
        "        feat = self.bn(feat)\n",
        "        feat = self.drop(feat)\n",
        "        logits = self.cls(feat)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "        return {\"loss\": loss, \"logits\": logits}\n"
      ],
      "id": "1MoxpBxO4qqV"
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# model = RobertaLSTMClassifier(MODEL_NAME, LSTM_HIDDEN, DROPOUT, USE_LSTM)\n",
        "\n",
        "# # Count parameters (total & trainable) â€” works for any PyTorch model\n",
        "# import pandas as pd\n",
        "# import torch.nn as nn\n",
        "\n",
        "# def count_params(m: nn.Module):\n",
        "#     trainable = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "#     total     = sum(p.numel() for p in m.parameters())\n",
        "#     return trainable, total\n",
        "\n",
        "# rows = []\n",
        "# # Whole model\n",
        "# tr, tt = count_params(model)\n",
        "# rows.append({\"Module\": \"TOTAL\", \"Trainable\": tr, \"Total\": tt})\n",
        "\n",
        "# # If you want the split (adjust names to your class if different)\n",
        "# enc = getattr(model, \"roberta\", None) or getattr(model, \"encoder\", None)\n",
        "# lstm = getattr(model, \"lstm\", None)\n",
        "# cls  = getattr(model, \"classifier\", None)\n",
        "# bn   = getattr(model, \"bn\", None)\n",
        "# drop = getattr(model, \"dropout\", None)\n",
        "\n",
        "# for name, part in [(\"Encoder (RoBERTa)\", enc), (\"Head::lstm\", lstm),\n",
        "#                    (\"Head::bn\", bn), (\"Head::dropout\", drop), (\"Head::classifier\", cls)]:\n",
        "#     if part is not None:\n",
        "#         tr, tt = count_params(part)\n",
        "#         rows.append({\"Module\": name, \"Trainable\": tr, \"Total\": tt})\n",
        "\n",
        "# df_params = pd.DataFrame(rows)\n",
        "# df_params[\"Trainable (M)\"] = (df_params[\"Trainable\"]/1e6).round(3)\n",
        "# df_params[\"Total (M)\"]     = (df_params[\"Total\"]/1e6).round(3)\n",
        "# print(df_params)\n",
        "# df_params.to_csv(\"parameter_counts.csv\", index=False)\n",
        "# print(\"Saved parameter_counts.csv\")\n"
      ],
      "metadata": {
        "id": "DWgIig0Pg0Ik"
      },
      "id": "DWgIig0Pg0Ik",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- C. Network schematic to PNG ---\n",
        "# # If not installed:\n",
        "# %pip install torchviz graphviz\n",
        "\n",
        "# import torch\n",
        "# from torchviz import make_dot\n",
        "\n",
        "# # build one dummy batch\n",
        "# dummy = tokenizer([\"diagram probe\"]*2, padding=True, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "# dummy = {k: v.to(device) for k,v in dummy.items()}\n",
        "\n",
        "# model.eval()\n",
        "# out = model(**dummy)\n",
        "# logits = out[\"logits\"] if isinstance(out, dict) else out.logits\n",
        "\n",
        "# # Create graph (params=True to show parameter nodes)\n",
        "# dot = make_dot(logits, params=dict(model.named_parameters()))\n",
        "# dot.format = \"png\"\n",
        "# png_path = dot.render(\"roberta_lstm_schematic\")  # produces roberta_lstm_schematic.png\n",
        "# print(\"Saved:\", png_path)\n"
      ],
      "metadata": {
        "id": "fbyWglrGiIHh"
      },
      "id": "fbyWglrGiIHh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNRatnDm4qqV"
      },
      "source": [
        "# Train (RoBERTa)"
      ],
      "id": "oNRatnDm4qqV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roT7uPw94qqV"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title ðŸš€ Train RoBERTa(+LSTM)\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "model = RobertaLSTMClassifier(MODEL_NAME, LSTM_HIDDEN, DROPOUT, USE_LSTM)\n",
        "\n",
        "def compute_metrics_fn(p):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    probs = torch.softmax(torch.tensor(preds), dim=-1).numpy()[:,1]\n",
        "    y_pred = (probs >= 0.5).astype(int)\n",
        "    y_true = p.label_ids\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
        "    }\n",
        "\n",
        "    # Check if there is more than one class in y_true before calculating AUROC and AP\n",
        "    if len(np.unique(y_true)) > 1:\n",
        "        metrics[\"auroc\"] = roc_auc_score(y_true, probs)\n",
        "        metrics[\"ap\"] = average_precision_score(y_true, probs)\n",
        "    else:\n",
        "        print(\"Warning: Only one class present in y_true. Skipping AUROC and AP calculation.\")\n",
        "        metrics[\"auroc\"] = float('nan') # Use NaN to indicate missing value\n",
        "        metrics[\"ap\"] = float('nan') # Use NaN to indicate missing value\n",
        "\n",
        "\n",
        "    return metrics\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"outputs_roberta\",\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    logging_steps=50,\n",
        "    report_to=[], seed=SEED\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model, args=args, train_dataset=train_ds, eval_dataset=val_ds, compute_metrics=compute_metrics_fn)\n",
        "trainer.train()"
      ],
      "id": "roT7uPw94qqV"
    },
    {
      "cell_type": "code",
      "source": [
        "###new trainer model\n",
        "#@title ðŸš€ Train RoBERTa(+LSTM)\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "model = RobertaLSTMAttentionClassifier(\n",
        "    MODEL_NAME,\n",
        "    LSTM_HIDDEN,\n",
        "    DROPOUT,\n",
        "    USE_LSTM\n",
        ")\n",
        "\n",
        "def compute_metrics_fn(p):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    probs = torch.softmax(torch.tensor(preds), dim=-1).numpy()[:,1]\n",
        "    y_pred = (probs >= 0.5).astype(int)\n",
        "    y_true = p.label_ids\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
        "    }\n",
        "\n",
        "    # Check if there is more than one class in y_true before calculating AUROC and AP\n",
        "    if len(np.unique(y_true)) > 1:\n",
        "        metrics[\"auroc\"] = roc_auc_score(y_true, probs)\n",
        "        metrics[\"ap\"] = average_precision_score(y_true, probs)\n",
        "    else:\n",
        "        print(\"Warning: Only one class present in y_true. Skipping AUROC and AP calculation.\")\n",
        "        metrics[\"auroc\"] = float('nan') # Use NaN to indicate missing value\n",
        "        metrics[\"ap\"] = float('nan') # Use NaN to indicate missing value\n",
        "\n",
        "\n",
        "    return metrics\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"outputs_roberta\",\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    logging_steps=50,\n",
        "    report_to=[], seed=SEED\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model, args=args, train_dataset=train_ds, eval_dataset=val_ds, compute_metrics=compute_metrics_fn)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "WpQQENQbuFOV"
      },
      "id": "WpQQENQbuFOV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Evaluate RoBERTa(+LSTM) on test set and save everything ===\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report,\n",
        "    roc_auc_score, average_precision_score,\n",
        "    roc_curve, precision_recall_curve\n",
        ")\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Predict probabilities and hard labels on test set\n",
        "pred = trainer.predict(test_ds)\n",
        "logits = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n",
        "probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()[:, 1]\n",
        "y_true = pred.label_ids\n",
        "y_pred = (probs >= 0.5).astype(int)\n",
        "\n",
        "# 2) Core metrics\n",
        "acc  = accuracy_score(y_true, y_pred)\n",
        "prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "print(\"=== RoBERTa(+LSTM) â€” Test Metrics (Ï„=0.5) ===\")\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall   : {rec:.4f}\")\n",
        "print(f\"F1       : {f1:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "# 3) AUROC & AP (guard for single-class y_true)\n",
        "has_both_classes = len(np.unique(y_true)) > 1\n",
        "if has_both_classes:\n",
        "    auroc = roc_auc_score(y_true, probs)\n",
        "    ap    = average_precision_score(y_true, probs)\n",
        "    print(f\"AUROC    : {auroc:.4f}\")\n",
        "    print(f\"AP       : {ap:.4f}\")\n",
        "else:\n",
        "    auroc, ap = float('nan'), float('nan')\n",
        "    print(\"Warning: Only one class present in y_true â€” skipping AUROC and AP.\")\n",
        "\n",
        "# 4) Confusion matrix (counts) + save figure\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title(\"Confusion Matrix â€” RoBERTa(+LSTM)\")\n",
        "plt.colorbar()\n",
        "ticks = np.arange(2)\n",
        "plt.xticks(ticks, [\"Truthful (0)\",\"Deceptive (1)\"])\n",
        "plt.yticks(ticks, [\"Truthful (0)\",\"Deceptive (1)\"])\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'), ha=\"center\", va=\"center\")\n",
        "plt.ylabel(\"True label\"); plt.xlabel(\"Predicted label\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"cm_roberta_lstm.png\", dpi=160)\n",
        "plt.show()\n",
        "\n",
        "# 5) ROC curve (if valid) + save\n",
        "if has_both_classes:\n",
        "    fpr, tpr, _ = roc_curve(y_true, probs)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"AUROC = {auroc:.3f}\")\n",
        "    plt.plot([0,1],[0,1], linestyle=\"--\")\n",
        "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve â€” RoBERTa(+LSTM)\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True, linestyle=\":\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"roc_curve_roberta_lstm.png\", dpi=160)\n",
        "    plt.show()\n",
        "\n",
        "# 6) Precisionâ€“Recall curve (if valid) + save\n",
        "if has_both_classes:\n",
        "    precisions, recalls, _ = precision_recall_curve(y_true, probs)\n",
        "    plt.figure()\n",
        "    plt.plot(recalls, precisions, label=f\"AP = {ap:.3f}\")\n",
        "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "    plt.title(\"Precisionâ€“Recall Curve â€” RoBERTa(+LSTM)\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.grid(True, linestyle=\":\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"pr_curve_roberta_lstm.png\", dpi=160)\n",
        "    plt.show()\n",
        "\n",
        "# 7) Save metrics to CSV for reporting\n",
        "metrics_row = {\n",
        "    \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1,\n",
        "    \"auroc\": auroc, \"ap\": ap, \"threshold\": 0.5,\n",
        "    \"seed\": SEED, \"use_lstm\": USE_LSTM,\n",
        "    \"max_len\": MAX_LEN, \"epochs\": EPOCHS,\n",
        "    \"batch_size\": BATCH_SIZE, \"learning_rate\": LEARNING_RATE, \"weight_decay\": WEIGHT_DECAY,\n",
        "}\n",
        "pd.DataFrame([metrics_row]).to_csv(\"roberta_lstm_test_metrics.csv\", index=False)\n",
        "print(\"Saved: roberta_lstm_test_metrics.csv, cm_roberta_lstm.png\",\n",
        "      \"(and ROC/PR curves if both classes present).\")\n",
        "\n",
        "# 8) Add to your comparison dict like other models\n",
        "results = globals().get(\"results\", {})\n",
        "results[\"RoBERTa_LSTM\"] = (acc, f1)\n",
        "print(\"\\nStored in results['RoBERTa_LSTM'] for comparison table.\")\n"
      ],
      "metadata": {
        "id": "j0prlJphrg8L"
      },
      "id": "j0prlJphrg8L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ðŸ“š Classical baselines on TF-IDF features\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.svm import LinearSVC\n",
        "# from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "# from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# def run_baseline(model_name, model, ngram_range=(1,1), use_liwc=False):\n",
        "#     print(f\"\\n=== {model_name} ===\")\n",
        "#     # TF-IDF setup\n",
        "#     tfidf = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=ngram_range)\n",
        "#     X_train_t = tfidf.fit_transform(X_train)\n",
        "#     X_test_t  = tfidf.transform(X_test)\n",
        "\n",
        "#     # (Optional) LIWC features placeholder\n",
        "#     # if use_liwc:  add psycholinguistic features here\n",
        "\n",
        "#     model.fit(X_train_t, y_train)\n",
        "#     y_pred = model.predict(X_test_t)\n",
        "#     acc = accuracy_score(y_test, y_pred)\n",
        "#     f1  = f1_score(y_test, y_pred)\n",
        "#     print(f\"Accuracy={acc:.4f}  F1={f1:.4f}\")\n",
        "#     return acc, f1\n",
        "\n",
        "# #results = {}\n",
        "\n",
        "# # SVM (unigram)\n",
        "# results[\"SVM_unigram\"] = run_baseline(\n",
        "#     \"SVM (unigram)\", LinearSVC(), ngram_range=(1,1))\n",
        "\n",
        "# # SVM (bigram)\n",
        "# results[\"SVM_bigram\"] = run_baseline(\n",
        "#     \"SVM (bigram)\", LinearSVC(), ngram_range=(2,2))\n",
        "\n",
        "# # SAGA (logistic regression solver)\n",
        "# results[\"SAGA\"] = run_baseline(\n",
        "#     \"Logistic (SAGA)\", LogisticRegression(max_iter=2000, solver=\"saga\"))\n",
        "\n",
        "# # You can approximate 'LIWC' versions later if you have LIWC lexicon counts.\n"
      ],
      "metadata": {
        "id": "GQTsRkMGGNlw"
      },
      "id": "GQTsRkMGGNlw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title â¬‡ï¸ Install and imports\n",
        "# !pip -q install transformers==4.44.2 scikit-learn==1.5.1 matplotlib==3.9.0 torch==2.3.1 -U\n",
        "\n",
        "# import os, re, unicodedata, random, numpy as np, pandas as pd, torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import accuracy_score, f1_score\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "# from sklearn.decomposition import TruncatedSVD\n",
        "# from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
        "# from transformers import AutoTokenizer\n",
        "\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# print(\"Device:\", device)\n",
        "\n",
        "# SEED = 42\n",
        "# random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "# torch.backends.cudnn.deterministic = True\n",
        "# torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "7NO9X95AJmSv"
      },
      "id": "7NO9X95AJmSv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# #@title ðŸ”¡ Tokenization & Dataloaders\n",
        "# MAX_LEN = 128  #@param {type:\"integer\"}\n",
        "# tok = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n",
        "\n",
        "# def encode_texts(texts, max_len=MAX_LEN):\n",
        "#     enc = tok(pd.Series(texts).tolist(), truncation=True, padding=True, max_length=max_len, return_tensors=\"pt\")\n",
        "#     return enc[\"input_ids\"], enc[\"attention_mask\"]\n",
        "\n",
        "# train_ids, train_mask = encode_texts(X_train)\n",
        "# val_ids,   val_mask   = encode_texts(X_val)\n",
        "# test_ids,  test_mask  = encode_texts(X_test)\n",
        "\n",
        "# ytr = torch.tensor(y_train, dtype=torch.long)\n",
        "# yva = torch.tensor(y_val, dtype=torch.long)\n",
        "# yte = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# train_loader = DataLoader(TensorDataset(train_ids, train_mask, ytr), batch_size=32, shuffle=True)\n",
        "# val_loader   = DataLoader(TensorDataset(val_ids, val_mask, yva), batch_size=32)\n",
        "# test_loader  = DataLoader(TensorDataset(test_ids, test_mask, yte), batch_size=32)\n",
        "\n",
        "# VOCAB_SIZE = tok.vocab_size\n",
        "# EMBED_DIM  = 128\n",
        "# NUM_CLASSES = 2\n"
      ],
      "metadata": {
        "id": "WwEQgC4GJcEb"
      },
      "id": "WwEQgC4GJcEb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# #@title ðŸ§ª Training helpers\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# def train_epoch(model, loader, optim, criterion):\n",
        "#     model.train()\n",
        "#     total = 0.0\n",
        "#     for ids, mask, labels in loader:\n",
        "#         ids = ids.to(device); labels = labels.to(device)\n",
        "#         optim.zero_grad()\n",
        "#         logits = model(ids)\n",
        "#         loss = criterion(logits, labels)\n",
        "#         loss.backward(); optim.step()\n",
        "#         total += loss.item()*ids.size(0)\n",
        "#     return total/len(loader.dataset)\n",
        "\n",
        "# @torch.no_grad()\n",
        "# def eval_model(model, loader):\n",
        "#     model.eval()\n",
        "#     preds=[]; trues=[]\n",
        "#     for ids, mask, labels in loader:\n",
        "#         ids=ids.to(device)\n",
        "#         p = F.softmax(model(ids), dim=-1)[:,1].cpu().numpy()\n",
        "#         yhat = (p>=0.5).astype(int)\n",
        "#         preds.extend(list(yhat)); trues.extend(list(labels.numpy()))\n",
        "#     return accuracy_score(trues, preds), f1_score(trues, preds)\n",
        "\n",
        "# def fit_model(model, train_loader, val_loader, epochs=5, lr=1e-3, wd=1e-4):\n",
        "#     model = model.to(device)\n",
        "#     opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "#     crit = nn.CrossEntropyLoss()\n",
        "#     for ep in range(1, epochs+1):\n",
        "#         tr_loss = train_epoch(model, train_loader, opt, crit)\n",
        "#         va_acc, va_f1 = eval_model(model, val_loader)\n",
        "#         print(f\"Epoch {ep}: train_loss={tr_loss:.4f}  val_acc={va_acc:.4f}  val_f1={va_f1:.4f}\")\n",
        "#     te_acc, te_f1 = eval_model(model, test_loader)\n",
        "#     return te_acc, te_f1\n"
      ],
      "metadata": {
        "id": "X2N_4xRHJ-oP"
      },
      "id": "X2N_4xRHJ-oP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# #@title ðŸ§  TextCNN\n",
        "# class TextCNN(nn.Module):\n",
        "#     def __init__(self, vocab_size, embed_dim=128, num_classes=2, kernels=(3,4,5), channels=128, dropout=0.5):\n",
        "#         super().__init__()\n",
        "#         self.emb = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "#         self.convs = nn.ModuleList([nn.Conv1d(embed_dim, channels, k) for k in kernels])\n",
        "#         self.drop = nn.Dropout(dropout)\n",
        "#         self.fc = nn.Linear(channels*len(kernels), num_classes)\n",
        "#     def forward(self, ids):\n",
        "#         x = self.emb(ids).transpose(1,2)\n",
        "#         outs = [F.relu(c(x)).max(dim=2)[0] for c in self.convs]\n",
        "#         x = torch.cat(outs, dim=1)\n",
        "#         x = self.drop(x)\n",
        "#         return self.fc(x)\n",
        "\n",
        "# textcnn = TextCNN(VOCAB_SIZE, EMBED_DIM, NUM_CLASSES)\n",
        "# acc_textcnn, f1_textcnn = fit_model(textcnn, train_loader, val_loader, epochs=5)\n",
        "# print(f\"TextCNN Test: Acc={acc_textcnn:.4f}  F1={f1_textcnn:.4f}\")\n"
      ],
      "metadata": {
        "id": "eV2TbwY2I8Vw"
      },
      "id": "eV2TbwY2I8Vw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# #@title ðŸ§  RCNN (BiLSTM + Conv)\n",
        "# class RCNN(nn.Module):\n",
        "#     def __init__(self, vocab_size, embed_dim=128, lstm_hidden=128, conv_channels=128, kernels=(3,4), num_classes=2, dropout=0.5):\n",
        "#         super().__init__()\n",
        "#         self.emb = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "#         self.lstm = nn.LSTM(embed_dim, lstm_hidden, batch_first=True, bidirectional=True)\n",
        "#         self.convs = nn.ModuleList([nn.Conv1d(2*lstm_hidden, conv_channels, k) for k in kernels])\n",
        "#         self.drop = nn.Dropout(dropout)\n",
        "#         self.fc = nn.Linear(conv_channels*len(kernels), num_classes)\n",
        "#     def forward(self, ids):\n",
        "#         x = self.emb(ids)\n",
        "#         x,_ = self.lstm(x)\n",
        "#         x = x.transpose(1,2)\n",
        "#         outs = [F.relu(c(x)).max(dim=2)[0] for c in self.convs]\n",
        "#         x = torch.cat(outs, dim=1)\n",
        "#         x = self.drop(x)\n",
        "#         return self.fc(x)\n",
        "\n",
        "# rcnn = RCNN(VOCAB_SIZE, EMBED_DIM)\n",
        "# acc_rcnn, f1_rcnn = fit_model(rcnn, train_loader, val_loader, epochs=5)\n",
        "# print(f\"RCNN Test:   Acc={acc_rcnn:.4f}  F1={f1_rcnn:.4f}\")\n"
      ],
      "metadata": {
        "id": "LREY2G7WKXt1"
      },
      "id": "LREY2G7WKXt1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# #@title ðŸ§  DRCNN (Dilated Residual CNN; approx DRI-RCNN)\n",
        "# class DilatedResBlock(nn.Module):\n",
        "#     def __init__(self, channels, dilation):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv1d(channels, channels, 3, padding=dilation, dilation=dilation)\n",
        "#         self.bn1 = nn.BatchNorm1d(channels)\n",
        "#         self.conv2 = nn.Conv1d(channels, channels, 3, padding=dilation, dilation=dilation)\n",
        "#         self.bn2 = nn.BatchNorm1d(channels)\n",
        "#     def forward(self, x):\n",
        "#         identity = x\n",
        "#         out = F.relu(self.bn1(self.conv1(x)))\n",
        "#         out = self.bn2(self.conv2(out))\n",
        "#         return F.relu(out + identity)\n",
        "\n",
        "# class DRCNN(nn.Module):\n",
        "#     def __init__(self, vocab_size, embed_dim=128, base_channels=128, dilations=(1,2,4), num_classes=2, dropout=0.5):\n",
        "#         super().__init__()\n",
        "#         self.emb = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "#         self.proj = nn.Conv1d(embed_dim, base_channels, kernel_size=1)\n",
        "#         self.blocks = nn.ModuleList([DilatedResBlock(base_channels, d) for d in dilations])\n",
        "#         self.drop = nn.Dropout(dropout)\n",
        "#         self.fc = nn.Linear(base_channels, num_classes)\n",
        "#     def forward(self, ids):\n",
        "#         x = self.emb(ids).transpose(1,2)\n",
        "#         x = self.proj(x)\n",
        "#         for blk in self.blocks:\n",
        "#             x = blk(x)\n",
        "#         x = F.adaptive_max_pool1d(x, 1).squeeze(-1)\n",
        "#         x = self.drop(x)\n",
        "#         return self.fc(x)\n",
        "\n",
        "# drcnn = DRCNN(VOCAB_SIZE, EMBED_DIM)\n",
        "# acc_drcnn, f1_drcnn = fit_model(drcnn, train_loader, val_loader, epochs=5)\n",
        "# print(f\"DRCNN Test:  Acc={acc_drcnn:.4f}  F1={f1_drcnn:.4f}\")\n"
      ],
      "metadata": {
        "id": "OS511ldiKjjH"
      },
      "id": "OS511ldiKjjH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# #@title ðŸ§  MFNN (CNN + TF-IDF projection)\n",
        "# TFIDF_MAX = 20000\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# tfidf = TfidfVectorizer(stop_words=\"english\", max_features=TFIDF_MAX, ngram_range=(1,2))\n",
        "# Xtf_train = tfidf.fit_transform(X_train)\n",
        "# Xtf_val   = tfidf.transform(X_val)\n",
        "# Xtf_test  = tfidf.transform(X_test)\n",
        "\n",
        "# svd_dim = 200\n",
        "# svd = TruncatedSVD(n_components=svd_dim, random_state=SEED)\n",
        "# Z_train = svd.fit_transform(Xtf_train)\n",
        "# Z_val   = svd.transform(Xtf_val)\n",
        "# Z_test  = svd.transform(Xtf_test)\n",
        "\n",
        "# class CNNPlusTFIDF(nn.Module):\n",
        "#     def __init__(self, vocab_size, embed_dim=128, kernels=(3,4,5), channels=128, aux_dim=200, num_classes=2, dropout=0.5):\n",
        "#         super().__init__()\n",
        "#         self.emb = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "#         self.convs = nn.ModuleList([nn.Conv1d(embed_dim, channels, k) for k in kernels])\n",
        "#         self.aux = nn.Linear(aux_dim, 128)\n",
        "#         self.drop = nn.Dropout(dropout)\n",
        "#         self.fc = nn.Linear(channels*len(kernels)+128, num_classes)\n",
        "#     def forward(self, ids, aux):\n",
        "#         x = self.emb(ids).transpose(1,2)\n",
        "#         outs = [F.relu(c(x)).max(dim=2)[0] for c in self.convs]\n",
        "#         x = torch.cat(outs, dim=1)\n",
        "#         a = torch.relu(self.aux(aux))\n",
        "#         x = torch.cat([x,a], dim=1)\n",
        "#         x = self.drop(x)\n",
        "#         return self.fc(x)\n",
        "\n",
        "# class AuxDataset(Dataset):\n",
        "#     def __init__(self, ids, masks, labels, aux_np):\n",
        "#         self.ids=ids; self.masks=masks; self.labels=labels; self.aux=torch.tensor(aux_np, dtype=torch.float32)\n",
        "#     def __len__(self): return len(self.labels)\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.ids[idx], self.masks[idx], self.labels[idx], self.aux[idx]\n",
        "\n",
        "# train_aux_loader = DataLoader(AuxDataset(train_ids, train_mask, ytr, Z_train), batch_size=32, shuffle=True)\n",
        "# val_aux_loader   = DataLoader(AuxDataset(val_ids, val_mask, yva, Z_val), batch_size=32)\n",
        "# test_aux_loader  = DataLoader(AuxDataset(test_ids, test_mask, yte, Z_test), batch_size=32)\n",
        "\n",
        "# def fit_model_aux(model, train_loader, val_loader, test_loader, epochs=5, lr=1e-3, wd=1e-4):\n",
        "#     model = model.to(device)\n",
        "#     opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "#     crit = nn.CrossEntropyLoss()\n",
        "#     for ep in range(1, epochs+1):\n",
        "#         model.train(); tr_loss=0.0\n",
        "#         for ids, mask, labels, aux in train_loader:\n",
        "#             ids=ids.to(device); labels=labels.to(device); aux=aux.to(device)\n",
        "#             opt.zero_grad()\n",
        "#             loss = crit(model(ids, aux), labels)\n",
        "#             loss.backward(); opt.step()\n",
        "#             tr_loss += loss.item()*ids.size(0)\n",
        "#         va_acc, va_f1 = eval_aux(model, val_loader)\n",
        "#         print(f\"Epoch {ep}: train_loss={tr_loss/len(train_loader.dataset):.4f}  val_acc={va_acc:.4f}  val_f1={va_f1:.4f}\")\n",
        "#     te_acc, te_f1 = eval_aux(model, test_loader)\n",
        "#     return te_acc, te_f1\n",
        "\n",
        "# @torch.no_grad()\n",
        "# def eval_aux(model, loader):\n",
        "#     model.eval(); preds=[]; trues=[]\n",
        "#     for ids, mask, labels, aux in loader:\n",
        "#         ids=ids.to(device); aux=aux.to(device)\n",
        "#         p = F.softmax(model(ids, aux), dim=-1)[:,1].cpu().numpy()\n",
        "#         preds.extend(list((p>=0.5).astype(int))); trues.extend(list(labels.numpy()))\n",
        "#     return accuracy_score(trues, preds), f1_score(trues, preds)\n",
        "\n",
        "# mfnn = CNNPlusTFIDF(VOCAB_SIZE, EMBED_DIM, aux_dim=svd_dim)\n",
        "# acc_mfnn, f1_mfnn = fit_model_aux(mfnn, train_aux_loader, val_aux_loader, test_aux_loader, epochs=5)\n",
        "# print(f\"MFNN Test:    Acc={acc_mfnn:.4f}  F1={f1_mfnn:.4f}\")\n"
      ],
      "metadata": {
        "id": "G53ZS1stLrFE"
      },
      "id": "G53ZS1stLrFE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# #@title ðŸ§  SOM-CNN (tiny SOM on SVD-TFIDF)\n",
        "# import numpy as np\n",
        "\n",
        "# som_dim = (8,8)\n",
        "# codebook_dim = Z_train.shape[1]\n",
        "# rng = np.random.default_rng(SEED)\n",
        "# codebook = rng.normal(0,0.1,size=(som_dim[0]*som_dim[1], codebook_dim))\n",
        "\n",
        "# def bmu(x, codebook):\n",
        "#     d = ((codebook - x)**2).sum(axis=1)\n",
        "#     return int(np.argmin(d))\n",
        "\n",
        "# def som_train(data, codebook, iters=400, init_lr=0.3, final_lr=0.05):\n",
        "#     m = codebook.shape[0]\n",
        "#     grid_xy = np.stack(np.unravel_index(np.arange(m), som_dim), axis=1)\n",
        "#     max_radius = max(som_dim)\n",
        "#     for t in range(iters):\n",
        "#         lr = init_lr + (final_lr - init_lr) * (t/iters)\n",
        "#         i = rng.integers(0, data.shape[0])\n",
        "#         x = data[i]\n",
        "#         j = bmu(x, codebook)\n",
        "#         bj = grid_xy[j]\n",
        "#         sigma = max(1.0, max_radius * (1 - t/iters))\n",
        "#         d2 = ((grid_xy - bj)**2).sum(axis=1)\n",
        "#         h = np.exp(-d2/(2*(sigma**2)))\n",
        "#         codebook += lr * h[:,None] * (x - codebook)\n",
        "#     return codebook\n",
        "\n",
        "# print(\"Training small SOM...\")\n",
        "# codebook = som_train(Z_train, codebook)\n",
        "\n",
        "# def som_feats(Z, codebook):\n",
        "#     feats = np.zeros((Z.shape[0], codebook.shape[0]), dtype=np.float32)\n",
        "#     for i in range(Z.shape[0]):\n",
        "#         feats[i, bmu(Z[i], codebook)] = 1.0\n",
        "#     return feats\n",
        "\n",
        "# S_train = som_feats(Z_train, codebook)\n",
        "# S_val   = som_feats(Z_val, codebook)\n",
        "# S_test  = som_feats(Z_test, codebook)\n",
        "\n",
        "# class SOMCNN(nn.Module):\n",
        "#     def __init__(self, vocab_size, embed_dim=128, kernels=(3,4,5), channels=128, som_dim=64, num_classes=2, dropout=0.5):\n",
        "#         super().__init__()\n",
        "#         self.emb = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "#         self.convs = nn.ModuleList([nn.Conv1d(embed_dim, channels, k) for k in kernels])\n",
        "#         self.sproj = nn.Linear(som_dim, 128)\n",
        "#         self.drop = nn.Dropout(dropout)\n",
        "#         self.fc = nn.Linear(channels*len(kernels)+128, num_classes)\n",
        "#     def forward(self, ids, som_vec):\n",
        "#         x = self.emb(ids).transpose(1,2)\n",
        "#         outs = [F.relu(c(x)).max(dim=2)[0] for c in self.convs]\n",
        "#         x = torch.cat(outs, dim=1)\n",
        "#         s = torch.relu(self.sproj(som_vec))\n",
        "#         x = torch.cat([x,s], dim=1)\n",
        "#         x = self.drop(x)\n",
        "#         return self.fc(x)\n",
        "\n",
        "# class SomDataset(Dataset):\n",
        "#     def __init__(self, ids, masks, labels, som_np):\n",
        "#         self.ids=ids; self.masks=masks; self.labels=labels; self.som=torch.tensor(som_np, dtype=torch.float32)\n",
        "#     def __len__(self): return len(self.labels)\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.ids[idx], self.masks[idx], self.labels[idx], self.som[idx]\n",
        "\n",
        "# train_som_loader = DataLoader(SomDataset(train_ids, train_mask, ytr, S_train), batch_size=32, shuffle=True)\n",
        "# val_som_loader   = DataLoader(SomDataset(val_ids, val_mask, yva, S_val), batch_size=32)\n",
        "# test_som_loader  = DataLoader(SomDataset(test_ids, test_mask, yte, S_test), batch_size=32)\n",
        "\n",
        "# def fit_model_som(model, train_loader, val_loader, test_loader, epochs=5, lr=1e-3, wd=1e-4):\n",
        "#     model = model.to(device)\n",
        "#     opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "#     crit = nn.CrossEntropyLoss()\n",
        "#     for ep in range(1, epochs+1):\n",
        "#         model.train(); tr_loss=0.0\n",
        "#         for ids, mask, labels, som_vec in train_loader:\n",
        "#             ids=ids.to(device); labels=labels.to(device); som_vec=som_vec.to(device)\n",
        "#             opt.zero_grad()\n",
        "#             loss = crit(model(ids, som_vec), labels)\n",
        "#             loss.backward(); opt.step()\n",
        "#             tr_loss += loss.item()*ids.size(0)\n",
        "#         va_acc, va_f1 = eval_som(model, val_loader)\n",
        "#         print(f\"Epoch {ep}: train_loss={tr_loss/len(train_loader.dataset):.4f}  val_acc={va_acc:.4f}  val_f1={va_f1:.4f}\")\n",
        "#     te_acc, te_f1 = eval_som(model, test_loader)\n",
        "#     return te_acc, te_f1\n",
        "\n",
        "# @torch.no_grad()\n",
        "# def eval_som(model, loader):\n",
        "#     model.eval(); preds=[]; trues=[]\n",
        "#     for ids, mask, labels, som_vec in loader:\n",
        "#         ids=ids.to(device); som_vec=som_vec.to(device)\n",
        "#         p = F.softmax(model(ids, som_vec), dim=-1)[:,1].cpu().numpy()\n",
        "#         preds.extend(list((p>=0.5).astype(int))); trues.extend(list(labels.numpy()))\n",
        "#     return accuracy_score(trues, preds), f1_score(trues, preds)\n",
        "\n",
        "# somcnn = SOMCNN(VOCAB_SIZE, EMBED_DIM, som_dim=S_train.shape[1])\n",
        "# acc_somcnn, f1_somcnn = fit_model_som(somcnn, train_som_loader, val_som_loader, test_som_loader, epochs=5)\n",
        "# print(f\"SOM-CNN Test: Acc={acc_somcnn:.4f}  F1={f1_somcnn:.4f}\")\n"
      ],
      "metadata": {
        "id": "5raoTqmQMXt_"
      },
      "id": "5raoTqmQMXt_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ---- First cell in a fresh runtime for GPU path ----\n",
        "# import os\n",
        "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # reduce noise\n",
        "# # (Do NOT set CUDA_VISIBLE_DEVICES here; we want GPU visible.)\n"
      ],
      "metadata": {
        "id": "ra6HU6VRPuPb"
      },
      "id": "ra6HU6VRPuPb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ---- Run this as the FIRST cell after Restart runtime ----\n",
        "# # Force CPU for the whole process (must be BEFORE importing torch)\n",
        "# import os\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # no GPUs visible\n",
        "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from torch import nn\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "# from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# # Assumes X_train, X_val, X_test, y_train, y_val, y_test are already created later.\n",
        "# # If not, put your CSV-loading + stratified split cells *above* this block or rerun them now.\n",
        "\n",
        "# class BertTextDataset(Dataset):\n",
        "#     def __init__(self, texts, labels, tok, max_len=256):\n",
        "#         self.texts = [str(t) for t in texts]\n",
        "#         self.labels = labels\n",
        "#         self.tok = tok\n",
        "#         self.max_len = max_len\n",
        "#     def __len__(self): return len(self.texts)\n",
        "#     def __getitem__(self, i):\n",
        "#         enc = self.tok(\n",
        "#             self.texts[i],\n",
        "#             padding=\"max_length\",\n",
        "#             truncation=True,\n",
        "#             max_length=self.max_len,\n",
        "#             return_tensors=\"pt\",\n",
        "#         )\n",
        "#         item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "#         item[\"labels\"] = torch.tensor(int(self.labels[i]), dtype=torch.long)\n",
        "#         return item\n",
        "\n",
        "# def run_bert_cpu(X_train, y_train, X_val, y_val, X_test, y_test, epochs=3, bs=16, lr=2e-5):\n",
        "#     device = torch.device(\"cpu\")\n",
        "#     tok = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n",
        "#     ds_tr = BertTextDataset(X_train, y_train, tok)\n",
        "#     ds_va = BertTextDataset(X_val,   y_val,   tok)\n",
        "#     ds_te = BertTextDataset(X_test,  y_test,  tok)\n",
        "\n",
        "#     tr = DataLoader(ds_tr, batch_size=bs, shuffle=True)\n",
        "#     va = DataLoader(ds_va, batch_size=bs)\n",
        "#     te = DataLoader(ds_te, batch_size=bs)\n",
        "\n",
        "#     model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "#     model.to(device)\n",
        "#     opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "#     loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#     def evaluate(loader):\n",
        "#         model.eval()\n",
        "#         probs, gold = [], []\n",
        "#         with torch.no_grad():\n",
        "#             for batch in loader:\n",
        "#                 for k in [\"input_ids\", \"attention_mask\", \"labels\"]:\n",
        "#                     batch[k] = batch[k].to(device)\n",
        "#                 out = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n",
        "#                 p = torch.softmax(out.logits, dim=-1)[:,1].cpu().numpy()\n",
        "#                 probs.extend(p.tolist())\n",
        "#                 gold.extend(batch[\"labels\"].cpu().numpy().tolist())\n",
        "#         preds = (np.array(probs) >= 0.5).astype(int)\n",
        "#         return accuracy_score(gold, preds), f1_score(gold, preds)\n",
        "\n",
        "#     # Train loop (CPU)\n",
        "#     for ep in range(1, epochs+1):\n",
        "#         model.train()\n",
        "#         running = 0.0\n",
        "#         for batch in tr:\n",
        "#             for k in [\"input_ids\", \"attention_mask\", \"labels\"]:\n",
        "#                 batch[k] = batch[k].to(device)\n",
        "#             out = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"], labels=batch[\"labels\"])\n",
        "#             loss = out.loss\n",
        "#             opt.zero_grad(); loss.backward(); opt.step()\n",
        "#             running += loss.item() * batch[\"input_ids\"].size(0)\n",
        "#         va_acc, va_f1 = evaluate(va)\n",
        "#         print(f\"Epoch {ep}: train_loss={running/len(ds_tr):.4f}  val_acc={va_acc:.4f}  val_f1={va_f1:.4f}\")\n",
        "\n",
        "#     te_acc, te_f1 = evaluate(te)\n",
        "#     print(f\"BERT Base â€” Test: Accuracy={te_acc:.4f}  F1={te_f1:.4f}\")\n",
        "#     return te_acc, te_f1\n",
        "\n",
        "# # Example usage *after* youâ€™ve created X_train/X_val/X_test/y_*:\n",
        "# # acc_bert, f1_bert = run_bert_cpu(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "# # results[\"BERT_Base\"] = (acc_bert, f1_bert)   # if you keep a comparison dict\n"
      ],
      "metadata": {
        "id": "SdCvaGiUMnTh"
      },
      "id": "SdCvaGiUMnTh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Example usage *after* youâ€™ve created X_train/X_val/X_test/y_*:\n",
        "# acc_bert, f1_bert = run_bert_cpu(X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "# # results[\"BERT_Base\"] = (acc_bert, f1_bert)   # if you keep a comparison dict"
      ],
      "metadata": {
        "id": "SD_PtgmBP3k6"
      },
      "id": "SD_PtgmBP3k6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results[\"BERT_Base\"] = (acc_bert, f1_bert)"
      ],
      "metadata": {
        "id": "6z2Xn4BGyYAg"
      },
      "id": "6z2Xn4BGyYAg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "id": "5vllwLB-ysur"
      },
      "id": "5vllwLB-ysur",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjIGRWis4qqV"
      },
      "source": [
        "plot like the paper"
      ],
      "id": "sjIGRWis4qqV"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# def add_result(name, acc, f1):\n",
        "#     \"\"\"\n",
        "#     name: model name as a string (how you want it to appear on the plot)\n",
        "#     acc, f1: either fractions (0â€“1) or percentages (70â€“100)\n",
        "#     in_percent: set True if you're passing 90.31 not 0.9031\n",
        "#     \"\"\"\n",
        "#     results[name] = (float(acc), float(f1))\n",
        "\n",
        "# # Example: add YOUR measured numbers (replace with your actual values)\n",
        "\n",
        "\n",
        "# add_result(\"RCNN\",                            0.8000, 0.8037)\n",
        "# # add_result(\"GRNN-CNN\",                        84.15, 84.17)\n",
        "# add_result(\"DRI-RCNN\",                        0.703,0.6025)\n",
        "# add_result(\"LDA with TextCNN\",                0.8063, 0.8239)\n",
        "# add_result(\"MFNN\",                            0.8125, 0.7959)\n",
        "# add_result(\"SOM-CNN\",                         0.8187, 0.8284)\n",
        "\n",
        "# # If you already computed RoBERTa+LSTM earlier:\n",
        "# # results[\"RoBERTa_LSTM\"] = (acc_rb, f1_rb)\n",
        "# # or set it manually:\n",
        "# print(results)\n"
      ],
      "metadata": {
        "id": "bog1Lp2L0GUk"
      },
      "id": "bog1Lp2L0GUk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Fix a canonical order for plotting/table\n",
        "# models_order = [\n",
        "#     \"SVM_bigram\",\n",
        "#     \"SVM_unigram\",\n",
        "#     \"SAGA\",\n",
        "#     \"RCNN\",\n",
        "#     \"GRNN-CNN\",\n",
        "#     \"DRI-RCNN\",\n",
        "#     \"BERT_Base\",\n",
        "#     \"LDA with TextCNN\",\n",
        "#     \"MFNN\",\n",
        "#     \"SOM-CNN\",\n",
        "#     \"RoBERTa_LSTM\",\n",
        "# ]\n",
        "\n",
        "# rows = []\n",
        "# for m in models_order:\n",
        "#     if m in results:\n",
        "#         acc, f1 = results[m]\n",
        "#         rows.append({\"Model\": m, \"Accuracy (%)\": round(acc*100, 2), \"F1-score (%)\": round(f1*100, 2)})\n",
        "\n",
        "# df_compare = pd.DataFrame(rows)\n",
        "# display(df_compare)\n",
        "# df_compare.to_csv(\"all_model_comparison.csv\", index=False)\n",
        "# print(\"Saved: all_model_comparison.csv\")\n"
      ],
      "metadata": {
        "id": "zfMnhfPJ1fqq"
      },
      "id": "zfMnhfPJ1fqq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# labels, accs, f1s = [], [], []\n",
        "# for m in models_order:\n",
        "#     if m in results:\n",
        "#         a, f = results[m]\n",
        "#         labels.append(m)\n",
        "#         accs.append(a*100.0)\n",
        "#         f1s.append(f*100.0)\n",
        "\n",
        "# x = np.arange(len(labels))\n",
        "# width = 0.35\n",
        "\n",
        "# plt.figure(figsize=(12,5))\n",
        "# plt.bar(x - width/2, accs, width, label='Op-Spam dataset Accuracy')\n",
        "# plt.bar(x + width/2, f1s,  width, label='Op-Spam dataset F1-score')\n",
        "\n",
        "# plt.xticks(x, labels, rotation=35, ha='right')\n",
        "# plt.ylabel('Score (%)')\n",
        "# plt.ylim(70, 100)          # match the paperâ€™s scale if you like\n",
        "# plt.title('Performance Comparison Under the Op-Spam dataset')\n",
        "# plt.legend()\n",
        "# plt.tight_layout()\n",
        "# plt.savefig(\"opspam_comparison_bars.png\", dpi=180)\n",
        "# plt.show()\n",
        "\n",
        "# print(\"Saved: opspam_comparison_bars.png\")\n"
      ],
      "metadata": {
        "id": "XL81KI642BTX"
      },
      "id": "XL81KI642BTX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}